[SNAPSHOT]
snapshot_interval_minutes = 10
compress_state = True

[MASKING]
masking = [
          {"regex_pattern": "(Mon|Tue|Wed|Thu|Fri|Sat|Sun)\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+(\\d{1,2})\\s+(\\d{1,2}:\\d{1,2}:\\d{1,2})(?:\\s+[A-Z]+)?\\s+(\\d{4})",  "mask_with": "*"},
          {"regex_pattern": "(?<=\\s)[A-Z]\\d{2}(?=\\s)", "mask_with": "*"},
          {"regex_pattern": "(<\\*>)(?:\\s+<\\*>)+", "mask_with": "*"},
          {"regex_pattern": "((?<=[^A-Za-z0-9])|^)(([0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4})((?=[^A-Za-z0-9])|$)", "mask_with": "*"},
          {"regex_pattern": "([\\w-]+\\.){2,}(com|net|org|cn|io|edu)(:\\d{1,5})?", "mask_with": "*"},
          {"regex_pattern": "(?:(?:https?|hdfs|ftp|tcp)://)?[\\w.-]+:\\d{1,5}(?=[\\s:;.,\\])}]|$)", "mask_with": "*"},
          {"regex_pattern": "(://|//|\\.?/)[^\\s)]+(?:/[^\\s)]*)*+/?(?<!:)(\\?[^\\s)]*)?", "mask_with": "*"},
          {"regex_pattern": "((?<=[^A-Za-z0-9])|^)(([0-9a-fA-F]{2,}:){3,}([0-9a-fA-F]{2,}))((?=[^A-Za-z0-9])|$)", "mask_with": "*"},
          {"regex_pattern": "((?<=[^A-Za-z0-9])|^)(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})((?=[^A-Za-z0-9])|$)", "mask_with": "*"},
          {"regex_pattern":"((?<=[^A-Za-z0-9])|^)(?:0[X]([A-F0-9]+)|0[x]([a-f0-9]+))((?=[^A-Za-z0-9])|$)|((?<=[^A-Za-z0-9])|^)([A-F0-9]{6,})((?=[^A-Za-z0-9])|$)|((?<=[^A-Za-z0-9])|^)([a-f0-9]{6,})((?=[^A-Za-z0-9])|$)", "mask_with": "*"},
          {"regex_pattern": "((?<=[^A-Za-z0-9])|^)([\\-\\+]?\\d+)((?=[^A-Za-z0-9])|$)", "mask_with": "*"},
          {"regex_pattern": "(?<![A-Za-z0-9])((B|KB|MB|GB|sec|secs|kbps))(?![A-Za-z0-9])", "mask_with": "*"},
          {"regex_pattern": "(?<=executed cmd )(\".+?\")", "mask_with": "*"}
          ]

mask_prefix = <
mask_suffix = >

[CONFIGURATION]
engine = vocabLog
sim_th = 0.0
depth = 500
max_children = 1000
max_clusters = 102400
parametrize_numeric_tokens = False

# True/False: Large Language Model is used or not
#LLM_support = False
LLM_support = True

# LLM provider, e.g., OpenAI, ModelScope, etc.
LLM_provider = https://api-inference.modelscope.cn/v1/
LLM_model = Qwen/Qwen3-235B-A22B
#LLM_model = Qwen/Qwen3-32B
#LLM_model = Qwen/Qwen3-8B
#LLM_model = gpt-4o

LLM_api_Key = "ms-66762aab-1ea5-4c85-a8ef-11d369d7dcca"

LLM_thinking = False
#LLM_thinking = True

[PROFILING]
enabled = True
report_sec = 1
